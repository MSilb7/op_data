{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "segment = 'method' # 'contract' # 'project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepend = 'csv_exports/whale_actions/'\n",
    "\n",
    "op_df = pd.read_csv(prepend + 'op_whale_actions_22_01_18.csv')\n",
    "op_df['chain'] = 'Optimism'\n",
    "\n",
    "l1_df = pd.read_csv(prepend + 'l1_whale_actions_22_01_18.csv')\n",
    "l1_df['chain'] = 'Ethereum'\n",
    "\n",
    "arb_df = pd.read_csv(prepend + 'arbi_whale_actions_22_01_18.csv')\n",
    "arb_df['chain'] = 'Arbitrum'\n",
    "\n",
    "df = pd.concat([op_df, l1_df, arb_df])\n",
    "df = df[df['project'] != '0x0000000000000000000000000000000000000000']\n",
    "df = df.fillna(0)\n",
    "\n",
    "# df.sample(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df.copy()\n",
    "df_merge['usd_value_in'] = np.where(df_merge['token_direction'] == 'in',df_merge['usd_value'], 0).astype(np.float64)\n",
    "df_merge['usd_value_out'] = np.where(df_merge['token_direction'] == 'out',df_merge['usd_value'], 0).astype(np.float64)\n",
    "df_merge = df_merge.groupby(['chain','address','project','contract','method']).sum()\n",
    "df_merge = df_merge.reset_index()\n",
    "\n",
    "df_merge['usd_value_net'] =  df_merge['usd_value_out'] - df_merge['usd_value_in'] # net in contracts\n",
    "df_merge['usd_value_net'] = np.where(df_merge['usd_value_net'] < 0, 0, df_merge['usd_value_net'])\n",
    "val_cols = ['usd_value','usd_value_in','usd_value_out','usd_value_net']\n",
    "display(df_merge.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addr = df_merge.groupby(['chain','address','project','contract','method']).sum()\n",
    "df_addr.reset_index(inplace=True)\n",
    "\n",
    "for val in val_cols:\n",
    "        df_addr[val + '_pct_share'] = df_addr.groupby(['address','chain'])[val].transform(lambda x: x / x.sum())\n",
    "display(df_addr.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = ['chain','project','contract','method']\n",
    "dlist = ['chain','project','contract','method','action'\\\n",
    "                ,'usd_value','usd_value_in','usd_value_out','usd_value_net'\\\n",
    "                ,'usd_value_pct_share','usd_value_in_pct_share','usd_value_out_pct_share','usd_value_net_pct_share'\n",
    "                ,'address' \\\n",
    "                ]\n",
    "\n",
    "if segment == 'project':\n",
    "        group_list.drop('method',inplace=True)\n",
    "        group_list.drop('contract',inplace=True)\n",
    "        dlist.drop('method',inplace=True)\n",
    "        dlist.drop('contract',inplace=True)\n",
    "elif segment == 'contract':\n",
    "        group_list.drop('method',inplace=True)\n",
    "        dlist.drop('method',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dollar = df_merge[['chain','project','contract','method','usd_value','usd_value_in','usd_value_out','usd_value_net','address']]\n",
    "df_dollar = df_dollar.groupby(['chain','project','contract','method']).agg({\n",
    "        'usd_value':'sum'\n",
    "        ,'usd_value_in':'sum'\n",
    "        ,'usd_value_out':'sum'\n",
    "        ,'usd_value_net':'sum'\n",
    "        ,'address':'nunique'\n",
    "})\n",
    "df_dollar.reset_index(inplace=True)\n",
    "df_dollar.name = 'df_dollar'\n",
    "for val in val_cols:\n",
    "        df_dollar[val + '_pct_share'] =  df_dollar[val] / ( df_dollar[val].sum() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average volume share across all whales\n",
    "# i.e. once someone is determined to be a whale, tkae their pct transfer share, and then we avg across rather than $ weight.\n",
    "# The reason to not dollar-weight is that we care more about genetating the average individual user experience, rather than the whaliest whale.\n",
    "\n",
    "df_action = df_addr.groupby(['chain','project','contract','method']).agg({\n",
    "        'usd_value_pct_share':'mean'\n",
    "        ,'usd_value_in_pct_share':'mean'\n",
    "        ,'usd_value_out_pct_share':'mean'\n",
    "        ,'usd_value_net_pct_share':'mean'\n",
    "        ,'usd_value':'mean'\n",
    "        ,'usd_value_in':'mean'\n",
    "        ,'usd_value_out':'mean'\n",
    "        ,'usd_value_net':'mean'\n",
    "        ,'address':'nunique'\n",
    "})\n",
    "\n",
    "df_action_by_app = df_addr.groupby(['chain','project','address']).agg({\n",
    "        # 'usd_value_pct_share':'mean'\n",
    "        # ,'usd_value_in_pct_share':'mean'\n",
    "        # ,'usd_value_out_pct_share':'mean'\n",
    "        # ,'usd_value_net_pct_share':'mean'\n",
    "        'usd_value':'sum'\n",
    "        ,'usd_value_in':'sum'\n",
    "        ,'usd_value_out':'sum'\n",
    "        ,'usd_value_net':'sum'\n",
    "})\n",
    "\n",
    "df_action_by_app.reset_index(inplace=True)\n",
    "\n",
    "for val in val_cols:\n",
    "        df_action_by_app[val + '_pct_share'] = df_action_by_app.groupby(['chain','address'])[val].transform(lambda x: x / x.sum())\n",
    "\n",
    "df_action_by_app = df_action_by_app.groupby(['chain','project']).agg({\n",
    "        'usd_value_pct_share':'mean'\n",
    "        ,'usd_value_in_pct_share':'mean'\n",
    "        ,'usd_value_out_pct_share':'mean'\n",
    "        ,'usd_value_net_pct_share':'mean'\n",
    "        ,'usd_value':'mean'\n",
    "        ,'usd_value_in':'mean'\n",
    "        ,'usd_value_out':'mean'\n",
    "        ,'usd_value_net':'mean'\n",
    "        ,'address':'nunique'\n",
    "})\n",
    "\n",
    "\n",
    "df_action.reset_index(inplace=True)\n",
    "df_action_by_app.reset_index(inplace=True)\n",
    "\n",
    "df_action.name = 'df_action'\n",
    "df_action_by_app.name = 'df_action_by_app'\n",
    "\n",
    "# display(df_action[df_action['project'] == 'gmx'])\n",
    "# display(df_action_by_app[df_action_by_app['project'] == 'gmx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_action, df_dollar]\n",
    "\n",
    "\n",
    "if not os.path.exists(\"csv_outputs\"):\n",
    "        os.mkdir(\"csv_outputs\")\n",
    "        \n",
    "for i, d in enumerate(dfs):\n",
    "        original_name = d.name\n",
    "        d.reset_index(inplace=True)\n",
    "        if segment == 'method':\n",
    "                d['action'] = d['project'].astype(str) + ' - ' + d['contract'].astype(str) + ' | ' + d['method'].astype(str)\n",
    "        elif segment == 'contract':\n",
    "                d['action'] = d['project'].astype(str) + ' - ' + d['contract'].astype(str)\n",
    "        elif segment == 'project':\n",
    "                d['action'] = d['project'].astype(str)\n",
    "        \n",
    "        # d = d[dlist]\n",
    "        \n",
    "        dfs[i] = d\n",
    "        d.name = original_name\n",
    "        \n",
    "#dumb hardcode, tried to do it fancy, but whatever\n",
    "df_action = dfs[0]\n",
    "df_dollar = dfs[1]\n",
    "\n",
    "df_action.to_csv('csv_outputs/whale_actions_share.csv')\n",
    "df_dollar.to_csv('csv_outputs/whale_actions_share_dollar_weight.csv')\n",
    "\n",
    "df_action.sample(20)\n",
    "# gix = px.pie(df_action, values='usd_value_out_pct_share', names='action', title='Share of Actions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['chain','project','action','usd_value_out','usd_value_out_pct_share','usd_value_net','usd_value_net_pct_share','address','style','granularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = 'Dollar-Weighted'\n",
    "print('Dollar-Weighted')\n",
    "chains = df_dollar['chain'].drop_duplicates().to_list()\n",
    "# print('Top Dollar Weighted Actions by Chain')\n",
    "dfs = []\n",
    "for c in chains:\n",
    "        tdf = df_dollar[df_dollar['chain'] == c]\n",
    "        sumdf = []\n",
    "        print('Sum by Action')\n",
    "        sumdf = tdf.groupby(['chain','project','action']).sum()\n",
    "        sumdf.reset_index(inplace=True)\n",
    "        \n",
    "        for val in val_cols:\n",
    "                sumdf[val + '_pct_share'] = sumdf.groupby(['chain'])[val].transform(lambda x: x / x.sum())\n",
    "        \n",
    "        # sumdf['usd_value_net_pct_share_100'] = sumdf['usd_value_net_pct_share'] * 100\n",
    "        # sumdf['usd_value_out_pct_share_100'] = sumdf['usd_value_out_pct_share'] * 100\n",
    "        sumdf = sumdf.sort_values(by = 'usd_value_out_pct_share', ascending = False)\n",
    "        sumdf['style'] = style\n",
    "        sumdf['granularity'] = 'action'\n",
    "        sumdf = sumdf[final_cols]\n",
    "        # display( sumdf.head(10) )\n",
    "        # display(sumdf.head())\n",
    "        dfs.append(sumdf)\n",
    "\n",
    "        print('Sum by App')\n",
    "        sumdf = []\n",
    "        sumdf = tdf.groupby(['chain','project']).sum()\n",
    "        sumdf.reset_index(inplace=True)\n",
    "        for val in val_cols:\n",
    "                sumdf[val + '_pct_share'] = sumdf.groupby(['chain'])[val].transform(lambda x: x / x.sum())\n",
    "\n",
    "        # sumdf['usd_value_net_pct_share_100'] = sumdf['usd_value_net_pct_share'] * 100\n",
    "        # sumdf['usd_value_out_pct_share_100'] = sumdf['usd_value_out_pct_share'] * 100\n",
    "        sumdf = sumdf.sort_values(by = 'usd_value_out_pct_share', ascending = False)\n",
    "        sumdf['style'] = style\n",
    "        sumdf['action'] = sumdf['project']\n",
    "        sumdf['granularity'] = 'project'\n",
    "        sumdf = sumdf[final_cols]\n",
    "        # display( sumdf.head(10) )\n",
    "        # display(sumdf.head())\n",
    "        dfs.append(sumdf)\n",
    "        # print(sumdf[['usd_value_out_pct_share_100']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = 'Address-Weighted'\n",
    "print(style)\n",
    "# print(df_action.columns)\n",
    "for c in chains:\n",
    "        tdf = df_action[df_action['chain'] == c]\n",
    "        # display(tdf)\n",
    "        tdf = tdf[tdf['address'] >=20]\n",
    "        sumdf = tdf\n",
    "        print('Sum by Action')\n",
    "        # sumdf = tdf.groupby(['chain','project','action']).sum()\n",
    "        # for val in val_cols:\n",
    "        #         sumdf[val + '_pct_share'] = sumdf.groupby(['chain'])[val].transform(lambda x: x / x.sum())\n",
    "        sumdf = tdf.groupby(['chain','project','action']).mean()\n",
    "        sumdf.reset_index(inplace=True)\n",
    "        # print(sumdf.columns)\n",
    "        # sumdf['usd_value_net_pct_share_100'] = sumdf['usd_value_net_pct_share'] * 100\n",
    "        # sumdf['usd_value_out_pct_share_100'] = sumdf['usd_value_out_pct_share'] * 100\n",
    "        sumdf = sumdf.sort_values(by = 'usd_value_out_pct_share', ascending = False)\n",
    "        sumdf['style'] = style\n",
    "        sumdf['granularity'] = 'action'\n",
    "        sumdf = sumdf[final_cols]\n",
    "        # display( sumdf.head(10) )\n",
    "        # display(sumdf.head())\n",
    "        dfs.append(sumdf)\n",
    "\n",
    "        print('Sum by App')\n",
    "        sumdf = df_action_by_app[df_action_by_app['chain'] == c]\n",
    "        sumdf = sumdf[sumdf['address'] >=20]\n",
    "        # for val in val_cols:\n",
    "        #         sumdf[val + '_pct_share'] = sumdf.groupby(['chain'])[val].transform(lambda x: x / x.sum())\n",
    "        sumdf = sumdf.groupby(['chain','project']).mean()\n",
    "        sumdf.reset_index(inplace=True)\n",
    "        # sumdf['usd_value_net_pct_share_100'] = sumdf['usd_value_net_pct_share'] * 100\n",
    "        # sumdf['usd_value_out_pct_share_100'] = sumdf['usd_value_out_pct_share'] * 100\n",
    "        sumdf = sumdf.sort_values(by = 'usd_value_out_pct_share', ascending = False)\n",
    "        sumdf['style'] = style\n",
    "        sumdf['action'] = sumdf['project']\n",
    "        sumdf['granularity'] = 'project'\n",
    "        sumdf = sumdf[final_cols]\n",
    "\n",
    "        # display(sumdf.head())\n",
    "        dfs.append(sumdf)\n",
    "        # display( sumdf.head(10) )\n",
    "        # print(sumdf[['usd_value_out_pct_share_100']].sum()) #SHould be > 100 since it's avg by address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_export = pd.concat(dfs)\n",
    "pd_export = pd_export[pd_export['usd_value_out_pct_share'] > (0.01 / 100) ] # greater than 0.01 %\n",
    "pd_export.to_csv('csv_outputs/whale_agg_summary.csv')\n",
    "display(pd_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d537a1638226190f579d6fbb68604c1b09ebc740a69df557abedb49ad78e592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
